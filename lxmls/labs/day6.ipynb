{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6: Sequence Models in Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1 \n",
    "Convince yourself a RNN is just an MLP with inputs and outputs at various layers. Run the NumpyRNN code. Set break-points and compare with what you learned about back-propagation in the previous day.\n",
    "\n",
    "Start by loading data Part-of-speech data and configure it for the exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add tools\n",
    "# NOTE: This should only be needed if you do not stire the notebook on the lxmls root\n",
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of Part-of-Speech WSJ Data\n",
    "WSJ_TRAIN = \"../../data/train-02-21.conll\"\n",
    "WSJ_TEST = \"../../data/test-23.conll\"\n",
    "WSJ_DEV = \"../../data/dev-22.conll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Part-of-Speech data \n",
    "import lxmls.readers.pos_corpus as pcc\n",
    "corpus = pcc.PostagCorpus()\n",
    "train_seq = corpus.read_sequence_list_conll(WSJ_TRAIN, max_sent_len=15, max_nr_sent=1000)\n",
    "test_seq = corpus.read_sequence_list_conll(WSJ_TEST, max_sent_len=15, max_nr_sent=1000)\n",
    "dev_seq = corpus.read_sequence_list_conll(WSJ_DEV, max_sent_len=15, max_nr_sent=1000) \n",
    "# Redo indices so that they are consecutive. Also cast all data to numpy arrays\n",
    "# of int32 for compatibility with GPUs and theano.\n",
    "train_seq, test_seq, dev_seq = pcc.compacify(train_seq, test_seq, dev_seq, theano=True)\n",
    "# Get number of words and tags in the corpus\n",
    "nr_words = len(train_seq.x_dict)\n",
    "nr_tags = len(train_seq.y_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Move this to a later exercise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting embeddings for the vocabulary 3618/4786 \n",
      "24.4% missing embeddings, set to random\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Path\n",
    "EMBEDDINGS = \"../../data/senna_50\"\n",
    "import lxmls.deep_learning.embeddings as emb\n",
    "import os\n",
    "reload(emb)\n",
    "if not os.path.isfile(EMBEDDINGS):\n",
    "    emb.download_embeddings('senna_50', EMBEDDINGS)\n",
    "E = emb.extract_embeddings(EMBEDDINGS, train_seq.x_dict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lxmls.deep_learning.rnn' from '../../lxmls/deep_learning/rnn.pyc'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lxmls.deep_learning.rnn as rnns\n",
    "reload(rnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RNN configuration\n",
    "SEED = 1234       # Random seed to initialize weigths\n",
    "hidden_size = 20  # size of hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_rnn = rnns.NumpyRNN(E, hidden_size, nr_tags, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x0 = train_seq[0].x\n",
    "y0 = train_seq[0].y\n",
    "loos, p_y, p, y_rnn, h, z1, x = np_rnn.forward(x0, all_outputs=True, outputs=y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "numpy_rnn_gradients = np_rnn.grads(x0, y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2\n",
    "Scan is your friend, maybe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Complete the theano code for a RNN inside lxmls/deep learning/rnn.py. Use exercise 6.1 for a numpy example and 6.2 to learn how to handle scan. You only need to implement the forward pass. To debug modify and compile the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "rnn = rnns.RNN(E, hidden_size, nr_tags, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile theano function\n",
    "x = T.ivector('x')\n",
    "th_forward = theano.function([x], rnn._forward(x).T)\n",
    "np_forward = np_rnn.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert np.allclose(th_forward(x0), np_forward(x0)), \"Numpy and Theano forward pass differ!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are confident the forward pass is working you can test the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile function returning the list of gradients\n",
    "x = T.ivector('x')\n",
    "p_y = rnn._forward(x)\n",
    "y = T.ivector('y')\n",
    "F = -T.mean(T.log(p_y)[T.arange(y.shape[0]), y])\n",
    "grads_fun = theano.function([x, y], [T.grad(F, par) for par in rnn.param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare numpy and theano gradients\n",
    "theano_rnn_gradients = grads_fun(x0, y0)\n",
    "for n in range(len(theano_rnn_gradients)): \n",
    "    assert np.allclose(numpy_rnn_gradients[n], theano_rnn_gradients[n]), \"Numpy and Theano gradients differ in step n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
