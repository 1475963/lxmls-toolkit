import codecs
import numpy as np
import gzip
import codecs


import sys
sys.path.append("sequences/" )
from sequence import *
from sequence_list import *


data_dir = "../data/ptb-conll/"


en_train = data_dir+"en_train.txt"
en_test = data_dir+"en_test.txt"

pt_train = data_dir+"pt_train.txt"
pt_test = data_dir+"pt_test.txt"


class PostagCorpus:

    def __init__(self,lang,max_sent_len=15,train_sents=1000,dev_sents=200,test_sents=200):
        x_dict = {}
        int_to_word = []
        y_dict = {}
        int_to_pos = []
        max_sents = train_sents+dev_sents+test_sents
        if(lang == "en"):
            print "Reading English corpus"
            print "Reading %s"%en_train
            print "Max Len: %i"%max_sent_len
            print "Max Nr. Sentences: %i"%max_sents
            instance_list,x_dict,int_to_word,y_dict,int_to_pos = self.read_instances(en_train,x_dict,int_to_word,y_dict,int_to_pos,max_sent_len,max_sents)
            print len(instance_list)
            if(len(instance_list) < max_sents):
                print "Reading %s"%en_test
                instance_list2,x_dict,int_to_word,y_dict,int_to_pos = self.read_instances(en_test,x_dict,int_to_word,y_dict,int_to_pos,max_sent_len,(max_sents - len(instance_list)))
                instance_list.extend(instance_list2)
            print len(instance_list)
        else:
            print "Corpus unavailable for language: %s"%lang
        nr_sents = min(max_sents,len(instance_list))
        seq_list_train = Sequence_List(x_dict,int_to_word,y_dict,int_to_pos)
        seq_list_dev = Sequence_List(x_dict,int_to_word,y_dict,int_to_pos)
        seq_list_test = Sequence_List(x_dict,int_to_word,y_dict,int_to_pos)
        for i in xrange(nr_sents):
            sent = instance_list[i]
            if(i < train_sents):
                seq_list_train.add_sequence(sent[0],sent[1])
            elif(i < train_sents + dev_sents):
                seq_list_dev.add_sequence(sent[0],sent[1])
            else:
                seq_list_test.add_sequence(sent[0],sent[1])
        self.x_dict = x_dict
        self.y_dict = y_dict
        self.int_to_word = int_to_word
        self.int_to_pos = int_to_pos
        self.train = seq_list_train
        self.dev = seq_list_dev
        self.test = seq_list_test
        self.feature_extracted = True
        ## Collect counts word counts
        word_counts = {}
        for sent in instance_list:
            for word in sent[0]:
                if word not in word_counts:
                    word_counts[word] = 0
                word_counts[word] +=1
        self.word_counts = word_counts
            


    
    def read_instances(self,file,x_dict,int_to_word,y_dict,int_to_pos,max_sent_len,max_nr_sent):
                if file.endswith("gz"):
                    zf = gzip.open(file, 'rb')
                    reader = codecs.getreader("utf-8")
                    contents = reader( zf )
                else:
                    contents =  codecs.open(file,"r","utf-8")
                
                nr_sent = 0
                instances = []
                ex_x = []
                ex_y = []
                nr_types = len(x_dict)
                nr_pos = len(y_dict)
                for line in contents:
                    toks = line.split()
                    if (len(toks) <2):
                        #print "sent n %i size %i"%(nr_sent,len(ex_x)) 
                        if(len(ex_x) < max_sent_len and len(ex_x) > 1):
                            #print "accept"
                            nr_sent +=1
                            instances.append([ex_x,ex_y])
                        # else:
                        #     if(len(ex_x) <= 1):
                        #         print "refusing sentence of len 1"
                        if(nr_sent >= max_nr_sent):
                            break
                        ex_x = []
                        ex_y = []
                    else:
                        pos = toks[1]
                        word = toks[0]
                        if(word not in x_dict):
                            x_dict[word] = nr_types
                            nr_types += 1;
                            int_to_word.append(word)
                        if (pos not in y_dict):
                            y_dict[pos] = nr_pos
                            nr_pos +=1
                            int_to_pos.append(pos)
                        ex_x.append(x_dict[word])
                        ex_y.append(y_dict[pos])
                return instances,x_dict,int_to_word,y_dict,int_to_pos

            ## Returns all sentences with a given word
    def find_sentences_with_word(self,word,tset="train"):
        seq_idx = []
        target_w = self.x_dict[word]
        if(target_w == -1):
            return []
        if(tset == "train"):
            seq_list = self.train.seq_list
        elif(tset =="test"):
            seq_list = self.test.seq_list
        elif(tset == "dev" and self.dev != []):
            seq_list = self.dev.seq_list
        else:
            print "Training set does not exist"
            return []
        for sequence in seq_list:
            for word in sequence.x:
                if word == target_w:
                    seq_idx.append(sequence.nr)
        return seq_idx

    
    def build_dictionary(self):
        dictionary = {}
        for sequence in self.train.seq_list:
            for pos,word in enumerate(sequence.x):
                tag = sequence.y[pos]
                if word not in dictionary:
                    dictionary[word] = []
                if(tag not in dictionary[word]):
                    dictionary[word].append(tag)
        return dictionary

    
            
